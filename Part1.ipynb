{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ecee7d",
   "metadata": {},
   "source": [
    "# 1.1 Getting Correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb87c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_img = cv2.imread('cv_cover.jpg', cv2.IMREAD_GRAYSCALE)#lazem grayscale 3shan feature detection\n",
    "#print(book_img.shape)\n",
    "cap = cv2.VideoCapture('book.mov')\n",
    "ret, frame = cap.read()#read gets the first frame and ret is just a flag to check if successful\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)#lazem grayscale 3shan feature detection\n",
    "else:\n",
    "    raise ValueError(\"Error, Couldnt read from video.\")\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "#sift. to get keypoints and their descriptors\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(book_img, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(frame_gray, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed338e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#brute force matcher takes every descriptor in img and compares it to every descriptor in the other img and returns the best match\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(descriptors1, descriptors2, k=2)#k=2 means it will return the 2 best matches for each descriptor\n",
    "#y3ni lkol descriptor fe img1 2 matches fe img2\n",
    "#matches is a list of lists\n",
    "\n",
    "# Apply Lowe's ratio test\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if (m.distance/n.distance) < 0.75:\n",
    "        good_matches.append(m)\n",
    "\n",
    "#Take the top 50 good matches\n",
    "good_matches = sorted(good_matches, key=lambda x: x.distance)[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_img = cv2.drawMatches(book_img, keypoints1, frame_gray, keypoints2, good_matches, None, flags=2)\n",
    "# print(book_img.shape)\n",
    "# print(frame_gray.shape)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(matched_img, cmap='gray')\n",
    "plt.title(\"Top 50 Keypoint Matches\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130fe30a",
   "metadata": {},
   "source": [
    "# 1.2 Compute the Homography Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8092a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_homography(src_pts, dst_pts):\n",
    "    \n",
    "    #src_pts: List or array of (x, y) points in the first image\n",
    "    #dst_pts: Corresponding list or array of (x', y') points in the second image\n",
    "\n",
    "    if len(src_pts) < 4:\n",
    "        raise ValueError(\"Need at least 4 point correspondences.\")\n",
    "\n",
    "    A = []\n",
    "    for (x, y), (x_prime, y_prime) in zip(src_pts, dst_pts):\n",
    "        A.append([x, y, 1, 0, 0, 0, -x * x_prime, -y * x_prime])\n",
    "        A.append([0, 0, 0, x, y, 1, -x * y_prime, -y * y_prime])\n",
    "\n",
    "    A = np.array(A) #2nx8 matrix\n",
    "    b = np.array(dst_pts).reshape(-1)# Flatten the dst_pts array to make it a 1D array,x1',y1',x2',y2'...\n",
    "    # Solve Ah = b using least squares\n",
    "    h = np.linalg.lstsq(A, b, rcond=None)[0]# Get the least-squares solution\n",
    "    \n",
    "\n",
    "    H = np.append(h, 1).reshape((3, 3))#make h33 = 1 and reshape it to 3x3 matrix\n",
    "    return H\n",
    "\n",
    "\n",
    "def compute_homography_ransac(src_pts, dst_pts, threshold=5.0, max_iter=100):\n",
    "  \n",
    "    src_pts = np.array(src_pts)\n",
    "    dst_pts = np.array(dst_pts)\n",
    "    num_points = len(src_pts)\n",
    "    best_H = None\n",
    "    best_inliers = []\n",
    "    max_inliers = 0\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        #Randomly choose 4 correspondences\n",
    "        idxs = np.random.choice(num_points, 4, replace=False)\n",
    "        src_sample = src_pts[idxs]\n",
    "        dst_sample = dst_pts[idxs]\n",
    "\n",
    "        #Compute homography from the 4 points\n",
    "        H = compute_homography(src_sample, dst_sample)\n",
    "\n",
    "        #Apply H to all src_pts\n",
    "        src_hom = np.hstack([src_pts, np.ones((num_points, 1))])  # convert to homogeneous coordinates [x y 1]\n",
    "        proj = (H @ src_hom.T).T \n",
    "        proj /= proj[:, 2][:, np.newaxis]  #convert back to hetergeneous coordinates\n",
    "\n",
    "        #Compute reprojection error\n",
    "        error = np.linalg.norm(proj[:, :2] - dst_pts, axis=1)\n",
    "\n",
    "        #Count inliers\n",
    "        inliers = error < threshold\n",
    "        num_inliers = np.sum(inliers)\n",
    "\n",
    "        if num_inliers > max_inliers:\n",
    "            max_inliers = num_inliers\n",
    "            best_H = H\n",
    "            best_inliers = inliers\n",
    "\n",
    "    #recompute H using all inliers\n",
    "    if max_inliers >= 4:\n",
    "        best_H = compute_homography(src_pts[best_inliers], dst_pts[best_inliers])\n",
    "    else:\n",
    "        raise ValueError(\"Not enough inliers found.\")\n",
    "\n",
    "    return best_H, best_inliers\n",
    "\n",
    "\n",
    "def apply_homography(H, points):\n",
    "    #Apply the homography matrix to the points.\n",
    "\n",
    "    points_hom = np.hstack([points, np.ones((len(points), 1))])  # Convert to homogeneous coordinates [x y 1]\n",
    "    transformed = (H @ points_hom.T).T  # Matrix multiplication to apply the homography\n",
    "\n",
    "    # Convert back to Cartesian coordinates(2D) by dividing by the last coordinate\n",
    "    transformed /= transformed[:, 2][:, np.newaxis]\n",
    "    return transformed[:, :2]## Keep only the x and y coordinates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches])\n",
    "dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches])\n",
    "\n",
    "original_book_img = cv2.imread(\"cv_cover.jpg\")  \n",
    "first_frame = frame.copy()\n",
    "H_test, _ = compute_homography_ransac(src_pts, dst_pts) \n",
    "\n",
    "# Store clicked points\n",
    "clicked_points = {\n",
    "    \"book\": [],\n",
    "    \"frame\": []\n",
    "}\n",
    "\n",
    "def click_event_book(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:#on left click take the x,y coordinates of the click\n",
    "        pt = np.array([[x, y]])\n",
    "        clicked_points[\"book\"].append((x, y))\n",
    "        frame_pt = apply_homography(H_test, pt)[0]\n",
    "        # Transform from book to frame\n",
    "        clicked_points[\"frame\"].append(tuple(frame_pt))\n",
    "\n",
    "        draw_and_update()\n",
    "\n",
    "def click_event_frame(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pt = np.array([[x, y]])\n",
    "        clicked_points[\"frame\"].append((x, y))\n",
    "\n",
    "        # Transform from frame to book\n",
    "        book_pt = apply_homography(np.linalg.inv(H_test), pt)[0] # applies inverse of H to get the book point\n",
    "        clicked_points[\"book\"].append(tuple(book_pt))\n",
    "\n",
    "        draw_and_update()\n",
    "\n",
    "def draw_and_update():\n",
    "    book_copy = original_book_img.copy()\n",
    "    frame_copy = first_frame.copy()\n",
    "\n",
    "    for pt in clicked_points[\"book\"]:\n",
    "        cv2.circle(book_copy, (int(pt[0]), int(pt[1])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    for pt in clicked_points[\"frame\"]:\n",
    "        cv2.circle(frame_copy, (int(pt[0]), int(pt[1])), 5, (0, 255, 0), -1)\n",
    "\n",
    "    cv2.imshow(\"Book Image\", book_copy)\n",
    "    cv2.imshow(\"Video Frame\", frame_copy)\n",
    "\n",
    "# Create windows and set mouse callbacks\n",
    "cv2.namedWindow(\"Book Image\")\n",
    "cv2.setMouseCallback(\"Book Image\", click_event_book)\n",
    "\n",
    "cv2.namedWindow(\"Video Frame\")\n",
    "cv2.setMouseCallback(\"Video Frame\", click_event_frame)\n",
    "\n",
    "# Initial draw\n",
    "draw_and_update()\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:  # ESC key to break\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d8b78",
   "metadata": {},
   "source": [
    "# 1.3 Calculate Book Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad913d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = book_img.shape[:2]\n",
    "book_corners = np.array([\n",
    "    [18, 4],\n",
    "    [w - 1, 3],\n",
    "    [w - 3, h - 3],\n",
    "    [16, h - 3]\n",
    "], dtype=np.float32)\n",
    "\n",
    "book_corners_proj = apply_homography(H_test, book_corners)\n",
    "book_corners_proj_int = np.int32(book_corners_proj)#Convert to integer coordinates only for drawing\n",
    "\n",
    "frame_with_corners = frame.copy()\n",
    "# cv2.polylines(frame_with_corners, [book_corners_proj_int], isClosed=True, color=(0, 0, 255), thickness=3)\n",
    "\n",
    "# Draw each corner\n",
    "for pt in book_corners_proj_int:\n",
    "    cv2.circle(frame_with_corners, tuple(pt), radius=3, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cv2.cvtColor(frame_with_corners, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Projected Book Corners on Video Frame\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba8134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the video\n",
    "# cap = cv2.VideoCapture('ar_source_2.mov')\n",
    "\n",
    "# # Read the first frame\n",
    "# ret, v_frame = cap.read()\n",
    "\n",
    "# if not ret:\n",
    "#     print(\"[ERROR] Failed to read the first frame from ar_source.mov.\")\n",
    "#     exit()\n",
    "\n",
    "# book_corners_int = np.int32(book_corners)\n",
    "# book_h, book_w = book_img.shape\n",
    "\n",
    "# # Get the book corner bounds\n",
    "# x_min, y_min = np.min(book_corners_int, axis=0)\n",
    "# x_max, y_max = np.max(book_corners_int, axis=0)\n",
    "\n",
    "# # Frame info\n",
    "# frame1_h, frame1_w = frame.shape[:2]\n",
    "# print(f\"[INFO] Book video frame shape: width={frame1_w}, height={frame1_h}\")\n",
    "\n",
    "# v_frame_height, v_frame_width = v_frame.shape[:2]\n",
    "# print(f\"[INFO] AR source frame shape: width={v_frame_width}, height={v_frame_height}\")\n",
    "\n",
    "# center_x, center_y = v_frame_width // 2, v_frame_height // 2\n",
    "# print(f\"[INFO] AR frame center: ({center_x}, {center_y})\")\n",
    "\n",
    "# # Crop dimensions and coordinates\n",
    "# crop_width = x_max - x_min\n",
    "# crop_height = y_max - y_min\n",
    "# print(f\"[INFO] Crop size: width={crop_width}, height={crop_height}\")\n",
    "\n",
    "# x_start = max(0, center_x - crop_width // 2)\n",
    "# x_end = min(v_frame_width, center_x + crop_width // 2)\n",
    "# y_start = max(0, center_y - crop_height // 2)\n",
    "# y_end = min(v_frame_height, center_y + crop_height // 2)\n",
    "\n",
    "# print(f\"[INFO] Cropping coordinates: x={x_start}:{x_end}, y={y_start}:{y_end}\")\n",
    "\n",
    "# # Crop and resize the AR frame\n",
    "# cropped_v_frame = v_frame[y_start:y_end, x_start:x_end]\n",
    "# print(f\"[INFO] Cropped AR frame shape: {cropped_v_frame.shape}\")\n",
    "\n",
    "# cropped_frame = cv2.resize(cropped_v_frame, (book_w, book_h))\n",
    "# print(f\"[INFO] Resized AR frame shape: {cropped_frame.shape}\")\n",
    "\n",
    "# # Display the cropped and resized AR frame\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.imshow(cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2RGB))\n",
    "# plt.title(\"Cropped and Resized AR Frame\")\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# # Prepare source and destination points for homography\n",
    "# hpanda, wpanda = cropped_frame.shape[:2]\n",
    "# src_pts = np.float32([[0, 0], [wpanda - 1, 0], [wpanda - 1, hpanda - 1], [0, hpanda - 1]])\n",
    "# dst_pts = book_corners_proj.astype(np.float32)\n",
    "\n",
    "# # Compute homography and warp\n",
    "# H_crop_to_book = compute_homography(src_pts, dst_pts)\n",
    "# warped_cropped = cv2.warpPerspective(cropped_frame, H_crop_to_book, (frame1_w, frame1_h))\n",
    "\n",
    "# print(f\"[INFO] Warped AR frame shape: {warped_cropped.shape}\")\n",
    "\n",
    "# # Display warped AR frame\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.imshow(cv2.cvtColor(warped_cropped, cv2.COLOR_BGR2RGB))\n",
    "# plt.title(\"Warped AR Frame\")\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# # Display the original video frame\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "# plt.title(\"Original Book Frame\")\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# # Create mask of non-black pixels in warped AR frame\n",
    "# gray_warp = cv2.cvtColor(warped_cropped, cv2.COLOR_BGR2GRAY)\n",
    "# _, mask = cv2.threshold(gray_warp, 10, 255, cv2.THRESH_BINARY)\n",
    "# mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "# # Prepare 3-channel masks\n",
    "# mask_3ch = cv2.merge([mask, mask, mask])\n",
    "# mask_inv_3ch = cv2.merge([mask_inv, mask_inv, mask_inv])\n",
    "\n",
    "# # Blend AR frame with original book frame\n",
    "# frame_bg = cv2.bitwise_and(frame, mask_inv_3ch)\n",
    "# overlay_fg = cv2.bitwise_and(warped_cropped, mask_3ch)\n",
    "# final_overlay = cv2.add(frame_bg, overlay_fg)\n",
    "\n",
    "# # Display final result\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.imshow(cv2.cvtColor(final_overlay, cv2.COLOR_BGR2RGB))\n",
    "# plt.title(\"Final AR Overlay on Book\")\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# # Release video capture\n",
    "# cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare video readers\n",
    "# book_cap = cv2.VideoCapture('book.mov')\n",
    "# ar_cap = cv2.VideoCapture('ar_source.mov')\n",
    "\n",
    "# frame_count = 0\n",
    "\n",
    "# book_corners_int = np.int32(book_corners)\n",
    "# book_h, book_w = book_img.shape\n",
    "\n",
    "# x_min, y_min = np.min(book_corners_int, axis=0)\n",
    "# x_max, y_max = np.max(book_corners_int, axis=0)\n",
    "# # Crop dimensions and coordinates\n",
    "# crop_width = x_max - x_min\n",
    "# crop_height = y_max - y_min\n",
    "\n",
    "# keypoints1, descriptors1 = sift.detectAndCompute(book_img, None)\n",
    "\n",
    "# while frame_count < 20:\n",
    "#     ret_book, frame_book = book_cap.read()\n",
    "#     ret_ar, ar_frame = ar_cap.read()\n",
    "\n",
    "#     if not ret_book or not ret_ar:\n",
    "#         print(f\"[ERROR] Could not read frame {frame_count} from one of the videos.\")\n",
    "#         break\n",
    "\n",
    "#     frame_count += 1\n",
    "#     print(f\"Processing frame {frame_count}\")\n",
    "\n",
    "#     frame_gray = cv2.cvtColor(frame_book, cv2.COLOR_BGR2GRAY)  # Convert to grayscale for feature detection\n",
    "\n",
    "#     ar_frame_height, ar_frame_width = ar_frame.shape[:2]\n",
    "#     center_x, center_y = ar_frame_width // 2, ar_frame_height // 2\n",
    "\n",
    "#     x_start = max(0, center_x - crop_width // 2)\n",
    "#     x_end = min(ar_frame_width, center_x + crop_width // 2)\n",
    "#     y_start = max(0, center_y - crop_height // 2)\n",
    "#     y_end = min(ar_frame_height, center_y + crop_height // 2)\n",
    "\n",
    "#     # Crop and resize the AR frame\n",
    "#     cropped_ar_frame = ar_frame[y_start:y_end, x_start:x_end]\n",
    "#     resized_cropped_ar_frame = cv2.resize(cropped_ar_frame, (book_w, book_h))\n",
    "\n",
    "#     keypoints2, descriptors2 = sift.detectAndCompute(frame_gray, None)\n",
    "#     matches = bf.knnMatch(descriptors1, descriptors2, k=2)  # k=2 means it will return the 2 best matches for each descriptor\n",
    "\n",
    "#     good_matches = []\n",
    "#     for m, n in matches:\n",
    "#         if (m.distance / n.distance) < 0.75:\n",
    "#             good_matches.append(m)\n",
    "\n",
    "#     good_matches = sorted(good_matches, key=lambda x: x.distance)[:50]\n",
    "#     matched_img = cv2.drawMatches(book_img, keypoints1, frame_gray, keypoints2, good_matches, None, flags=2)\n",
    "\n",
    "#     src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "#     dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "#     # Compute homography\n",
    "#     H = compute_homography(src_pts.reshape(-1, 2), dst_pts.reshape(-1, 2))\n",
    "#     h, w = book_img.shape\n",
    "\n",
    "#     book_corners = np.array([\n",
    "#         [18, 4],\n",
    "#         [w - 1, 3],\n",
    "#         [w - 3, h - 3],\n",
    "#         [16, h - 3]\n",
    "#     ], dtype=np.float32)\n",
    "\n",
    "#     book_corners_proj = apply_homography(H, book_corners)\n",
    "#     book_corners_proj_int = np.int32(book_corners_proj)  # Convert to integer coordinates for drawing\n",
    "\n",
    "#     hpanda, wpanda = resized_cropped_ar_frame.shape[:2]\n",
    "#     src_pts = np.float32([[0, 0], [wpanda - 1, 0], [wpanda - 1, hpanda - 1], [0, hpanda - 1]])\n",
    "#     dst_pts = book_corners_proj.astype(np.float32)\n",
    "\n",
    "#     # Compute homography to overlay AR frame onto the book\n",
    "#     H_crop_to_book = compute_homography(src_pts, dst_pts)\n",
    "#     warped_cropped = cv2.warpPerspective(resized_cropped_ar_frame, H_crop_to_book, (frame_book.shape[1], frame_book.shape[0]))\n",
    "\n",
    "#     # Create mask of non-black pixels in warped AR frame\n",
    "#     gray_warp = cv2.cvtColor(warped_cropped, cv2.COLOR_BGR2GRAY)\n",
    "#     _, mask = cv2.threshold(gray_warp, 10, 255, cv2.THRESH_BINARY)\n",
    "#     mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "#     # Prepare 3-channel masks\n",
    "#     mask_3ch = cv2.merge([mask, mask, mask])\n",
    "#     mask_inv_3ch = cv2.merge([mask_inv, mask_inv, mask_inv])\n",
    "\n",
    "#     # Blend AR frame with original book frame\n",
    "#     frame_bg = cv2.bitwise_and(frame_book, mask_inv_3ch)\n",
    "#     overlay_fg = cv2.bitwise_and(warped_cropped, mask_3ch)\n",
    "#     final_overlay = cv2.add(frame_bg, overlay_fg)\n",
    "\n",
    "#     # Display the cropped and resized AR frame\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.imshow(cv2.cvtColor(resized_cropped_ar_frame, cv2.COLOR_BGR2RGB))\n",
    "#     plt.title(\"Cropped and Resized AR Frame\")\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "#     # Display final result\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.imshow(cv2.cvtColor(final_overlay, cv2.COLOR_BGR2RGB))\n",
    "#     plt.title(\"Final AR Overlay on Book\")\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "#     out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'XVID'), 30, (final_overlay.shape[1], final_overlay.shape[0]))\n",
    "#     out.write(final_overlay)\n",
    "\n",
    "#     cv2.waitKey(3)  # Wait a bit to allow the next frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c9cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "book_cap = cv2.VideoCapture('book.mov')\n",
    "ar_cap = cv2.VideoCapture('ar_source_2.mov')\n",
    "sift = cv2.SIFT_create()\n",
    "bf = cv2.BFMatcher()\n",
    "count=0\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(book_img, None)\n",
    "\n",
    "book_h, book_w = book_img.shape\n",
    "book_corners = np.float32([[18, 4], [book_w - 1, 3], [book_w - 3, book_h - 3], [16, book_h - 3]])\n",
    "\n",
    "# Get video properties\n",
    "fps = book_cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(book_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(book_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_overlay.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret_book, frame_book = book_cap.read()\n",
    "    ret_ar, frame_ar = ar_cap.read()\n",
    "\n",
    "    if not ret_book or not ret_ar:\n",
    "        break\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame_book, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(frame_gray, None)\n",
    "\n",
    "\n",
    "    \n",
    "    if descriptors2 is None or len(descriptors2) < 2:\n",
    "        out.write(frame_book)\n",
    "        continue\n",
    "\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]\n",
    "\n",
    "    if len(good_matches) > 10:\n",
    "        src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches])\n",
    "        dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches])\n",
    "\n",
    "        H,_= compute_homography_ransac(src_pts, dst_pts)\n",
    "        if H is not None:\n",
    "            book_corners_proj = apply_homography(H,book_corners)\n",
    "\n",
    "            \n",
    "            # Center crop AR frame using book image size\n",
    "            ar_h, ar_w = frame_ar.shape[:2]\n",
    "            crop_h, crop_w = book_h, book_w\n",
    "\n",
    "            center_y, center_x = ar_h // 2, ar_w // 2\n",
    "            y1 = max(center_y - crop_h // 2, 0)\n",
    "            y2 = min(center_y + crop_h // 2, ar_h)\n",
    "            x1 = max(center_x - crop_w // 2, 0)\n",
    "            x2 = min(center_x + crop_w // 2, ar_w)\n",
    "\n",
    "            cropped_ar = frame_ar[y1:y2, x1:x2]\n",
    "            resized_ar = cv2.resize(cropped_ar, (book_w, book_h))\n",
    "            \n",
    "            # count+=1\n",
    "            # if count==1:\n",
    "            #     plt.figure(figsize=(10, 8))\n",
    "            #     plt.imshow(cv2.cvtColor(cropped_ar, cv2.COLOR_BGR2RGB))\n",
    "            #     plt.title(\"Cropped and Resized AR Frame\")\n",
    "            #     print(f\"cropped_ar shape: {cropped_ar.shape}\")\n",
    "            #     plt.figure(figsize=(10, 8))\n",
    "            #     plt.imshow(cv2.cvtColor(resized_ar, cv2.COLOR_BGR2RGB))\n",
    "            #     plt.title(\"Cropped and Resized AR Frame\")\n",
    "            #     print(f\"resized_ar shape: {resized_ar.shape}\")\n",
    "\n",
    "\n",
    "            ###hpanda, wpanda = resized_ar.shape[:2]\n",
    "\n",
    "            ###src_pts_ar = np.float32([[0, 0], [wpanda - 1, 0], [wpanda - 1, hpanda - 1], [0, hpanda - 1]])\n",
    "            dst_pts_ar = book_corners_proj.astype(np.float32)\n",
    "\n",
    "            ###H_ar_to_book,_ = compute_homography_ransac(src_pts_ar, dst_pts_ar)\n",
    "            warped_ar = cv2.warpPerspective(resized_ar, H, (frame_book.shape[1], frame_book.shape[0]))\n",
    "            # plt.figure(figsize=(10, 8))\n",
    "            # plt.imshow(cv2.cvtColor(warped_ar, cv2.COLOR_BGR2RGB))\n",
    "            # plt.title(\"Cropped and Resized AR Frame\")\n",
    "            # Masking\n",
    "            # Create a blank mask the same size as the frame\n",
    "            mask_bin = np.zeros((frame_book.shape[0], frame_book.shape[1]), dtype=np.uint8)\n",
    "\n",
    "            # Fill the projected book area as white (255)\n",
    "            cv2.fillConvexPoly(mask_bin, np.int32(dst_pts_ar), 255)\n",
    "\n",
    "            mask_inv = cv2.bitwise_not(mask_bin)\n",
    "            mask_3ch = cv2.merge([mask_bin] * 3)\n",
    "            mask_inv_3ch = cv2.merge([mask_inv] * 3)\n",
    "\n",
    "            bg = cv2.bitwise_and(frame_book, mask_inv_3ch)\n",
    "            fg = cv2.bitwise_and(warped_ar, mask_3ch)\n",
    "            overlay = cv2.add(bg, fg)\n",
    "\n",
    "            out.write(overlay)\n",
    "        else:\n",
    "            out.write(frame_book)\n",
    "    else:\n",
    "        out.write(frame_book)\n",
    "\n",
    "book_cap.release()\n",
    "ar_cap.release()\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
